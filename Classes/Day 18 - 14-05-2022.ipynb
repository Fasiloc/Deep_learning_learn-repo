{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c17cfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Importing both TensorFlow and its high level API - Keras.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# Setting the random seeds for repeatability\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "181227f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (60000, 28, 28)\n",
      "Shape of X_test:  (10000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load MNIST database of handwritten digits\n",
    "mnistDB = keras.datasets.mnist\n",
    "# Training Dataset of 60,000 28x28 grayscale images of the 10 digits,\n",
    "# along with a test set of 10,000 images.\n",
    "(X_train, y_train),(X_test, y_test) = mnistDB.load_data()\n",
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "# Shape of X_train: (60000, 28, 28)\n",
    "print(\"Shape of X_test: \", X_test.shape)\n",
    "# Shape of X_test: (10000, 28, 28)\n",
    "# We can view the dataset with matplotlib\n",
    "plt.imshow(X_train[1], cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fb362ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (60000, 784)\n",
      "Shape of X_test:  (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# All 60000 training images are converted to 1D representation.\n",
    "X_train = X_train.reshape((60000, 28*28))\n",
    "# The grayscale image pixels are unsigned values between 0 and 255.\n",
    "# These pixels need to be normalized to the range 0 to 1 for DNN.\n",
    "# So, the entire training data is converted to 32-bit float and then\n",
    "# divided with 255 to bring down the range to 0 to 1.\n",
    "X_train = X_train.astype('float32')/255\n",
    "# Similar operations are done to 10000 testing images.\n",
    "# Flattening 2D image to 1D representation.\n",
    "X_test = X_test.reshape((10000, 28*28))\n",
    "# Scale pixel values to range 0 to 1.\n",
    "X_test = X_test.astype('float32')/255\n",
    "# Check again the shape of both training and testing dataset.\n",
    "# Both are now 1D representations.\n",
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "# Shape of X_train: (60000, 784)\n",
    "print(\"Shape of X_test: \", X_test.shape)\n",
    "# Shape of X_test: (10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "737ceb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 50)                39250     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                1530      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                310       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,090\n",
      "Trainable params: 41,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create neural network using keras API\n",
    "# Sequential() does linear stacking of layers\n",
    "dnnModel_MNIST = keras.models.Sequential()\n",
    "# Hidden layer definitions.\n",
    "# The input layer is defined together with\n",
    "# first hidden layer by specifying the input_shape.\n",
    "dnnModel_MNIST.add(keras.layers.Dense(50, activation=\"relu\",\n",
    "input_shape=X_train.shape[1:]))\n",
    "dnnModel_MNIST.add(keras.layers.Dense(30, activation=\"relu\"))\n",
    "# Output layer\n",
    "dnnModel_MNIST.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "# Print the summary of network architecture\n",
    "dnnModel_MNIST.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef321fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
      "Epoch 1/10\n",
      "3375/3375 [==============================] - 5s 1ms/step - loss: 0.2895 - accuracy: 0.9147 - val_loss: 0.1300 - val_accuracy: 0.9620\n",
      "Epoch 2/10\n",
      "3375/3375 [==============================] - 4s 1ms/step - loss: 0.1384 - accuracy: 0.9588 - val_loss: 0.1051 - val_accuracy: 0.9683\n",
      "Epoch 3/10\n",
      "3375/3375 [==============================] - 4s 1ms/step - loss: 0.1019 - accuracy: 0.9685 - val_loss: 0.1018 - val_accuracy: 0.9728\n",
      "Epoch 4/10\n",
      "3375/3375 [==============================] - 4s 1ms/step - loss: 0.0852 - accuracy: 0.9732 - val_loss: 0.1010 - val_accuracy: 0.9707\n",
      "Epoch 5/10\n",
      "3375/3375 [==============================] - 4s 1ms/step - loss: 0.0691 - accuracy: 0.9780 - val_loss: 0.0945 - val_accuracy: 0.9732\n",
      "Epoch 6/10\n",
      "3375/3375 [==============================] - 4s 1ms/step - loss: 0.0600 - accuracy: 0.9809 - val_loss: 0.1058 - val_accuracy: 0.9712\n",
      "Epoch 7/10\n",
      "3375/3375 [==============================] - 5s 1ms/step - loss: 0.0508 - accuracy: 0.9840 - val_loss: 0.1021 - val_accuracy: 0.9748\n",
      "Epoch 8/10\n",
      "3375/3375 [==============================] - 4s 1ms/step - loss: 0.0457 - accuracy: 0.9853 - val_loss: 0.1019 - val_accuracy: 0.9760\n",
      "Epoch 9/10\n",
      "3375/3375 [==============================] - 5s 1ms/step - loss: 0.0396 - accuracy: 0.9870 - val_loss: 0.1058 - val_accuracy: 0.9757\n",
      "Epoch 10/10\n",
      "3375/3375 [==============================] - 5s 1ms/step - loss: 0.0351 - accuracy: 0.9887 - val_loss: 0.1040 - val_accuracy: 0.9740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x299488d6d30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the labels of the classes.\n",
    "# Since, they are numeric labels, we can safely go ahead.\n",
    "print(set(y_test))\n",
    "# {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
    "# Compile the network model with relevant configurations.\n",
    "# loss, optimizer and metrics are three important configurations.\n",
    "dnnModel_MNIST.compile(loss='sparse_categorical_crossentropy',\n",
    "optimizer='adam', metrics=['accuracy'])\n",
    "# Train the network with 60000 training dataset\n",
    "# with 10% of them used a validation set.\n",
    "dnnModel_MNIST.fit(x=X_train, y=y_train, validation_split=0.1, epochs=10,\n",
    "batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b6a1aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.1152 - accuracy: 0.9724\n",
      "0.11522817611694336 0.9724000096321106\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with the 10000 testing image dataset.\n",
    "# The function to evaluate the model returns two values,\n",
    "# output loss, and the accuracy.\n",
    "test_loss, test_accuracy = dnnModel_MNIST.evaluate(x=X_test, y=y_test)\n",
    "# Print the output loss and accuracy.\n",
    "# Depending on the computer used for evaluation,\n",
    "# the results might slightly vary.\n",
    "# The accuracy obtained can be close enough to what is obtained here\n",
    "print(test_loss, test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5420b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
